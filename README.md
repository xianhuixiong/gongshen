# 公平竞争合规审查系统

本仓库实现了一个基于人工智能大模型的公平竞争合规审查系统原型。用户可以通过 Web 页面输入业务方案、合同条款或平台规则等文本，系统会调用大模型对输入内容进行公平竞争与反垄断风险分析，生成风险评分、总结要点、列出潜在风险点并给出整改建议。该系统定位为内部合规辅助工具，不构成正式法律意见。

## 功能概述

- **业务类型选择**：支持不同的业务场景，例如通用竞争行为、合同条款（合作/分销/独家）、平台规则、招投标/采购、并购/集中申报等，以便模型更加精准地理解上下文。
- **法域选择**：可指定主要适用法域（中国大陆、欧盟、美国或多法域综合），用于生成适配不同法律体系的审查提示和建议。
- **文本输入**：用户输入需要审查的业务描述或条款全文，建议分段输入过长文本以提高分析准确性。
- **可选输出**：可勾选生成风险评分、列出关键风险点、给出整改建议等功能，灵活控制输出内容。
- **风险评分和等级**：模型根据输入内容给出 0–100 的风险评分，并用低、中、高三个等级进行标识，方便快速了解风险程度。
- **风险点列表**：对每个识别出的风险点给出标题、等级、问题说明、整改建议以及可能涉及的法律依据，帮助快速定位问题并采取改进措施。
- **审查结果总结**：提供简短的风险总结和模型分析局限性说明，提示用户在重大或复杂场景下咨询专业律师。

## 目录结构

```
fair-competition-review/
├── public/
│   └── index.html      前端单页应用源码
├── server.js          Node.js + Express 后端服务
├── package.json       项目依赖和脚本定义
└── README.md          项目说明与使用指南
```

## 快速开始

1. **安装依赖**

   在项目根目录执行以下命令安装必要的依赖：

   ```bash
   npm install
   ```

2. **启动服务**

   运行以下命令启动本地服务器：

   ```bash
   npm start
   ```

   默认情况下，服务会运行在 `http://localhost:3000`，浏览器访问即可使用。

3. **使用说明**

   - 在页面左侧选择业务场景、主要适用法域，并在文本框内粘贴需要审查的业务内容或条款。
   - 根据需要勾选是否生成风险评分、风险点和整改建议。
   - 点击“开始审查”按钮，等待模型分析并在右侧显示结果。
   - 结果包括风险评分和等级、整体风险总结、详细风险点列表以及模型使用注意事项。

4. **替换大模型服务**

   当前 `server.js` 中的 `callLLM` 函数为示例实现，返回模拟结果。要接入真实的大模型服务，请按以下步骤修改：

   1. 按照大模型提供方的 API 文档或 SDK，在 `server.js` 中引入相应客户端或使用 `fetch` 调用 HTTP 接口。
   2. 在 `callLLM` 中构建请求，将 `buildPrompt` 生成的字符串作为 Prompt 参数发送给模型服务。
   3. 解析模型返回的 JSON 结构，并确保与前端约定的字段一致（`riskScore`、`summary`、`issues`、`modelNote`）。
   4. 注意对输入和模型输出的数据安全和隐私保护，避免泄露敏感信息。

5. **扩展建议**

   - **完善提示词**：根据业务场景和法域调整 Prompt 模板，更精细地引导大模型关注具体法律条文和典型案例。
   - **模板预设**：为常见业务类型设计审查模板，例如平台经济、代理分销、独家合作、招投标等，减少用户输入成本。
   - **审计与记录**：在后端对每次审查结果做脱敏记录，形成审查日志供内部审计部门留存（注意遵循隐私合规要求）。
   - **角色权限**：增加用户管理和权限控制，不同人员根据岗位查看对应的审查报告范围。
   - **多语言支持**：根据业务需求添加英文等多语言界面，便于跨国企业使用。

## 注意事项

本系统仅为技术原型，输出结果由大模型生成，存在理解偏差或法律适用不准确的风险，仅供企业内部合规参考。对重大交易或复杂垄断风险的合规审查，请务必咨询具备资质的法律专业人士。